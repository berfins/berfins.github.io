<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Publication Title - Berfin Sakallioglu</title>
    <link rel="stylesheet" href="style.css">
</head>

</head>
<body>

  <!-- Styled navigation matching index.html -->
  <nav>
    <a href="index.html#home">Hello!</a>
    <a href="index.html#publications">Publications</a>
        <a href="index.html#cv">CV</a>

  </nav>
  <div class="container">

  <h1>Combining Grammatical Evolution with LLM-based Local Search to Improve Interpretability

  <!-- ✅ Buttons now directly below the title -->
      <div class="publication-container">
    <a href="https://drive.google.com/file/d/1ZcBt-u6rBjQeHIOpNe0GTlincS8o3oaP/view?usp=sharing" target="_blank">PDF</a>
  </div>
</h1>


  <h2>Authors</h2>
  <p>Berfin Sakallioglu, Frederico J.J.B. Santos, Daniel Parra, Yuxin Qiu, Miguel Nicolau, Leonardo Trujillo and J. Ignacio Hidalgo</p>

  <h2>Publication Info</h2>
  <p>Conference Paper, 28th European Conference on Genetic Programming (EvoStar), Toulouse, France, 2026 <strong style="color: #526457;">(to appear)</strong> </p>

  <h2>Abstract</h2>
  <p>Interpretability is increasingly crucial in artificial intelligence, especially in domains like medicine, where genetic programming, particularly grammatical evolution (GE), can produce models that are potentially interpretable. However, optimizing for predictive accuracy often results in complex expressions that can reduce interpretability. Large language models (LLMs) offer a promising approach to simplify and interpret complex model expressions. Here, we propose incorporating an LLM-guided local search operator into GE to enhance model interpretability in symbolic regression and test this approach for medical prediction. The operator leverages the semantic reasoning and domain knowledge encoded in LLMs to refine candidate expressions through a parallel search mechanism complementary to traditional fitness-driven evolution. Our experiments, conducted on a clinical dataset for glycated hemoglobin prediction, showed that three LLM-guided variants improve interpretability compared to baseline GE, with two showing signs of possible overfitting and the other generalizing better. LLM-generated individuals demonstrated evolutionary viability throughout evolution and direct contribution to the final solutions. Comparison of proprietary and local LLMs revealed challenges with adherence to instructions and creative exploration in smaller models. These results indicate that the proposed approach is a promising strategy for obtaining simpler, more interpretable, and more plausible models.</p>
  </div>
<footer>
    © 2026, Berfin Sakallioglu.
</footer>

<script>
function toggleCitation(event) {
  event.preventDefault(); // stop link from jumping
  const box = document.getElementById('citation-box');
  if (box.style.display === 'none' || box.style.display === '') {
    box.style.display = 'block';
  } else {
    box.style.display = 'none';
  }
}
</script>

</body>
</html>
